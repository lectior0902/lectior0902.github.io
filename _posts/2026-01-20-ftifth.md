---
layout: single
title:  "프롬프트 엔지니어링 논문 2가지 분석"
---
<br/><br/>

프롬프트를 작성하다보니 CoT와 ToT의 개념이 중요하다는 것을 알게 되었다.
이에 따라 각각의 개념을 담은 논문을 분석해보고 인사이트를 도출해보고자 한다.


<br/><br/>

# Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (Wei et al., 2022)

<br/><br/>

### 1. CoT(Chain-of-Thought)의 핵심 작동 원리

LLM이 복잡한 산술(Arithmetic), 상식(Commonsense), 상징적(Symbolic) 추론에서 실패하는 이유는 '표준적인 답변 출력(Standard Prompting)' 방식 때문이다.
그러므로 인간이 어려운 수학 문제를 풀 때 연습장에 풀이 과정을 적듯, AI에게도 **'생각할 공간(Intermediate Steps)'** 을 제공해야 한다.

- 작동 기전: 입력(Input) → 사고의 사슬(Chain of Thought) → 출력(Output)의 3단계 구조를 통해, 모델은 각 토큰을 생성할 때 이전의 추론 단계에 의존(Conditioning)하게 되어 논리적 일관성을 유지한다.

<br/>

### 2. 4가지 핵심 기술 인사이트

<br/>

① Emergent Ability

CoT는 모든 모델에서 작동하는 것이 아니며 약 100B(1,000억 개) 이상의 파라미터를 가진 모델에서만 유의미한 효과가 나타나는 '능력'이다.

<br/>

② Variable Compute (변수 계산)

표준적인 프롬프트는 문제의 난이도와 상관없이 일정한 단계로 답을 내지만, CoT는 조금 다르다.

CoT는 모델이 더 많은 토큰을 생성하게 함으로써, 결과적으로 추론 시점에 **더 많은 연산량** 을 투입하게 만든다.
"단계별로 생각하라"는 CoT를 요구하는 명령은 모델의 연산 효율을 높이는 과정으로 이해해야 할 것.

<br/>

③ Robustness (견고성)

서로 다른 사람(Annotator)이 쓴 다양한 스타일의 CoT가 모두 효과적이었음이 증명됨.
즉, CoT는 어떠한 효과적인 코드나 명령어, 패턴 같은 것이 아니라, '논리적 구조'라는 점이 핵심.
그러므로 **논리 단위나 과정** 를 설계하는 것이 더욱 중요할 것이다.

<br/>

④ OOD(Out-of-Domain) 일반화와 길이 확장성
5절의 Symbolic Reasoning 실험 결과는 매우 중요합니다.

인사이트: CoT는 예시(Few-shot)로 본 것보다 더 길고 복잡한 문제(예: 2글자 합치기를 학습하고 4글자 합치기 해결)에 대해서도 일반화 성능을 보입니다.

전략: 복잡한 시스템 아키텍처를 설계할 때, 모든 케이스를 학습시키지 않아도 **'해결 로직의 패턴'**만 CoT로 잘 정의하면 미학습 영역(OOD)까지 대응할 수 있습니다.

<br/><br/>

## 📝 논문 분석 요약: Chain-of-Thought (CoT) Prompting

### 1. 개요
- **핵심 내용**: LLM에 중간 추론 단계(Intermediate reasoning steps)를 포함한 예시를 제공하여 논리적 추론 능력을 극대화함.
- **적용한 내용**: 산술 연산(GSM8K), 상식 추론(StrategyQA), 상징적 조작(Coin Flip) 등.

### 2. 시사점
- **Scale Matters**: CoT는 거대 모델(100B+)에서만 효과가 탁월함. 소형 모델은 Distillation이 필요.
- **Interpretability**: AI가 왜 그런 답을 냈는지 '추론 과정'을 텍스트로 볼 수 있기 때문에 디버깅과 이용자의 신뢰 확보에 유리함.
- **Algorithm as Prompt**: 프롬프트를 텍스트가 아닌 '단계별 알고리즘'으로 설계하여 모델의 추론 경로를 강제할 수 있음.


<br/><br/><br/><br/>




# Tree of Thoughts: Deliberate Problem Solving with Large Language Models (Yao et al., 2023)

<br/>

간단히 말해서, ToT는 모델이 여러 갈래의 생각을 스스로 검토하고 최적의 경로를 찾게 만드는 구조이다.

<br/><br/>

## 1. 개요
- **현상:** 기존의 IO(Input-Output)나 CoT(Chain-of-Thought)는 토큰을 순차적으로 생성하는 '빠르고 자동적인' 모드(**System 1**)에 의존한다.
- **문제:** 이에 따라 체스나 수학 문제처럼 '계획'과 '검토'가 필요한 복잡한 태스크에서는 한 번의 실수로 전체 경로가 무너지는 한계가 있음.
- **해결책:** 따라서 이 논문에서는 인간의 '신중하고 분석적인' 모습을 모방하여, 여러 대안을 탐색하고 스스로 평가하며 되돌아가는(Backtracking) 프레임워크를 제안하고 있음.

<br/>

## 2. ToT 프레임워크 아키텍처 (The 4 Components)

ToT는 문제를 '트리 탐색'으로 정의하며, 4가지 핵심 구성 요소로 이루어진다.

| 구성 요소 | 기술적 정의 | 비고 |
| :--- | :--- | :--- |
| **Thought Decomposition** | 전체 프로세스를 작은 '생각 단위(Thought)'로 쪼갬 | 문제에 따라 문장, 문단, 수식 등으로 정의 |
| **Thought Generator** | 현재 상태에서 다음 단계의 후보들을 생성 | i.i.d. 샘플링 혹은 Propose 프롬프트 활용 |
| **State Evaluator** | 각 후보(노드)가 정답에 가까운지 가치(Value)를 평가 | Sure/Likely/Impossible 등급 부여 혹은 투표 |
| **Search Algorithm** | 트리 구조를 탐색하는 알고리즘 적용 | BFS(너비 우선) 또는 DFS(깊이 우선) 탐색 |

[Image illustrating the Tree of Thoughts framework showing a root node expanding into branches of thoughts with evaluation scores and backtracking]

<br/>

## 3. 실험 결과 및 벤치마크 (PaLM 540B/GPT-4 기준)

- **Game of 24 (수학):** CoT(7.3%) 대비 **ToT(74%)** 로 성능 폭발적 향상.
- **Creative Writing (작문):** 문장 간의 일관성 및 계획성 평가에서 가장 높은 점수 획득.
- **Crosswords (낱말 맞추기):** DFS를 통한 백트래킹으로 복잡한 제약 조건을 해결.

<br/>

## 4. 🛠 인사이트

### ① 프롬프트의 중요성
- **Insight:** 이제 프롬프트는 단독으로 존재하지 않고, `Generator`와 `Evaluator`라는 모듈로 분리됨. 
- **Application:** 서비스 설계 시 단일 프롬프트에 의존하지 말고, **검증 로직(Validation Loop)**을 시스템 레벨에서 구현해야 함.

<br/>

### ② Inference-time Compute의 전략적 활용
- **Insight:** CoT가 선형적 연산량을 쓴다면, ToT는 트리 탐색을 위해 더 많은 토큰(비용/시간)을 소모함.
- **Application:** 비용 대비 정확도가 중요한 비즈니스 로직에서, 사용자에게 즉각 응답을 줄 부분(System 1)과 백그라운드에서 정교하게 처리할 부분을 분리하는 **Hybrid Inference 아키텍처**가 필요함.

<br/>

### ③ Backtracking
- **Insight:** ToT의 핵심은 "이 길이 아니다"라고 판단될 때 이전 노드로 돌아가는 능력.
- **Application:** LLM 기반 에이전트 구축 시, 현재 상태를 저장(State Management)하고 실패 시 롤백하여 다른 대안을 시도하는 **Stateful AI Workflow** 설계가 필수적임.

---


<br/><br/>



## 📝 논문 분석 정리

| 개념 | 핵심 키워드 | 인사이트 (Technical Insights) |
| :--- | :--- | :--- |
| **Chain-of-Thought (CoT)** | 중간 추론, Step-by-step | 모델의 논리적 사고를 유도하며, 추론 단계에 따라 연산 자원을 가변적으로 할당하는 최적화 전략 수립 가능 |
| **Tree of Thoughts (ToT)** | 다중 경로 탐색, 자가 평가 | 프롬프트를 단순 텍스트가 아닌 BFS/DFS 알고리즘 구조로 설계하여, AI 스스로 오류를 수정하는 자가 교정(Self-Correction) 루프 구현 가능 |









