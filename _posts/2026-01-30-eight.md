---
layout: single
title:  "26.01.27. 데일리미션: 데이터 시각화"
---

# 지수가중함수 (EWM), 그룹화 계산(Groupby) 파라미터 활용




```python
from google.colab import drive
drive.mount('/content/drive')
```


```python
!jupyter nbconvert --to markdown "/content/drive/MyDrive/구름 생성AI/구름exp/26.01.27 데일리미션.ipynb"
```

# **kaggle dataset**
- Twitter is one of the popular social media applications where people share what they feel in a limited number of words. Twitter is popular but not in the stock market.
- Twitter was founded in 2006 and was listed on the stock exchange in 2013. Since the founding of Twitter, 2022 has been an event to remember Twitter. As Elon Musk took over Twitter, it will be delisted from the New York Exchange. As 2022 was so eventful for Twitter, analyze the complete timeline of Twitter in the Stock Market from 2013 to 2022.



```python
import pandas as pd
```


```python
import numpy as np
```


```python
import matplotlib.pyplot as plt
```


```python
# Kaggle 데이터 로드
df = pd.read_csv('/Twitter Stock Market Dataset.csv')
print("데이터 크기:", df.shape)
```

    데이터 크기: (2264, 7)



```python
print(df.head(5))
```

             Date       Open       High        Low      Close  Adj Close  \
    0  2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002   
    1  2013-11-08  45.930000  46.939999  40.685001  41.650002  41.650002   
    2  2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   
    3  2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002   
    4  2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998   
    
            Volume  
    0  117701670.0  
    1   27925307.0  
    2   16113941.0  
    3    6316755.0  
    4    8688325.0  


#**지수가중함수 (EWM)**


```python
# Date 부분만 사용

df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date')
```


```python
# 20일치만 사용

df_20 = df.tail(20).reset_index()
```


```python
# Date를 문자열로 변환하여 막대와 선의 X축 좌표를 통일
df_20['Date'] = df_20['Date'].dt.strftime('%m-%d')
```


```python
# alpha=0.1로 해서 최근 가격 변동을 10% 반영하는 추세선을 만듦(df2)
df2 = df_20.assign(ewm_a_low=df_20['Close'].ewm(alpha=0.1).mean())

# alpha=0.7로 해서 최근 가격 변동을 70% 반영하는 추세선을 만듦(df3)
df3 = df_20.assign(ewm_a_high=df_20['Close'].ewm(alpha=0.7).mean())
```


```python
# 시각화
ax = df_20.plot(kind='bar', x='Date', y='Close')

# alpha = 0.1 빨간색
df2.plot(kind='line', x='Date', y='ewm_a_low', color='red', ax=ax, label='10%')

# alpha = 0.7 초록색
df3.plot(kind='line', x='Date', y='ewm_a_high', color='green', ax=ax, label='70%')

plt.xticks(rotation=45)
plt.show()
```


<img width="550" height="457" alt="26 01 27 데일리미션_13_0" src="https://github.com/user-attachments/assets/b2bfc26a-7aee-4e42-ae7f-ac96d619b25d" />


```python
# Y축 범위를 데이터의 최솟값 근처로 조정해서 시각적인 부분을 개선

ax = df_20.plot(kind='bar', x='Date', y='Close')

# alpha = 0.1 빨간색
df2.plot(kind='line', x='Date', y='ewm_a_low', color='red', ax=ax, label='10%')

# alpha = 0.7 초록색
df3.plot(kind='line', x='Date', y='ewm_a_high', color='green', ax=ax, label='70%')

plt.ylim(df_20['Close'].min() * 0.95, df_20['Close'].max() * 1.05)

plt.xticks(rotation=45)
plt.show()
```



<img width="550" height="457" alt="26 01 27 데일리미션_14_0" src="https://github.com/user-attachments/assets/5f216bed-f652-4b68-b999-dd20f827c675" />



##**span 인수 사용**


```python
# span=4, 약 4일간의 흐름을 반영
df_span4 = df_20.assign(span_4=df_20['Close'].ewm(span=4).mean())

# span=8, 약 8일간의 흐름을 반영
df_span8 = df_20.assign(span_8=df_20['Close'].ewm(span=8).mean())

# 시각화
ax = df_20.plot(kind='bar', x='Date', y='Close')

# span=4 (빨간색)
df_span4.plot(kind='line', x='Date', y='span_4', color='red', ax=ax)

# span=8 (초록색)
df_span8.plot(kind='line', x='Date', y='span_8', color='green', ax=ax)

# Y축 범위 조정
plt.ylim(df_20['Close'].min() * 0.95, df_20['Close'].max() * 1.05)


plt.xticks(rotation=45)
plt.show()
```



<img width="550" height="457" alt="26 01 27 데일리미션_16_0" src="https://github.com/user-attachments/assets/2af335c6-d51f-48bd-89d8-077cbeceed37" />





#**com 인수 사용**


```python
# a = 1/(1+com), com이 커질수록 a가 작아짐
# com=2는 질량 중심이 현재와 가까워 변동에 민감
df_com2 = df_20.assign(com_2=df_20['Close'].ewm(com=2).mean())

# com=10은 질량 중심이 과거 쪽으로 치우쳐 완만
df_com10 = df_20.assign(com_10=df_20['Close'].ewm(com=10).mean())

# 시각화
ax = df_20.plot(kind='bar', x='Date', y='Close')

# com=2 (빨간색)
df_com2.plot(kind='line', x='Date', y='com_2', color='red', ax=ax)

# com=10 (초록색)
df_com10.plot(kind='line', x='Date', y='com_10', color='green', ax=ax)

# Y축 범위 조정
plt.ylim(df_20['Close'].min() * 0.95, df_20['Close'].max() * 1.05)

plt.xticks(rotation=45)
plt.show()
```




    <img width="550" height="457" alt="26 01 27 데일리미션_18_0" src="https://github.com/user-attachments/assets/f38027df-d2e7-4745-93ee-756f85863f3f" />





#**halflife 인수 사용**


```python
# a = 1-e^(-ln(2)/halflife), halflife가 길어질수록 a가 작아짐
# halflife = 2: 영향력이 2일마다 반감 (최근 변동에 민감)
df2 = df_20.assign(harf_2=df_20['Close'].ewm(halflife=2).mean())

# halflife = 5: 영향력이 5일마다 반감 (과거 데이터를 더 오래 반영)
df3 = df_20.assign(harf_5=df_20['Close'].ewm(halflife=5).mean())

# 시각화
ax = df_20.plot(kind='bar', x='Date', y='Close')

# halflife=2 (빨간색)
df2.plot(kind='line', x='Date', y='harf_2', color='red', ax=ax)

# halflife=5 (초록색)
df3.plot(kind='line', x='Date', y='harf_5', color='green', ax=ax)

# Y축 범위 조정
plt.ylim(df_20['Close'].min() * 0.95, df_20['Close'].max() * 1.05)

plt.xticks(rotation=45)
plt.show()
```





<img width="550" height="457" alt="26 01 27 데일리미션_20_0" src="https://github.com/user-attachments/assets/102e3ee3-7641-46b8-b18f-e3776c4aea5c" />


    


#**adjust 인수 사용**


```python
# adjust 인수
df2_adj = df_20.assign(adj_True=df_20['Close'].ewm(alpha=0.2, adjust=True).mean())
df3_adj = df_20.assign(adj_False=df_20['Close'].ewm(alpha=0.2, adjust=False).mean())

# 시각화
ax = df_20.plot(kind='bar', x='Date', y='Close')

# adjust=True (빨간색)
df2_adj.plot(kind='line', x='Date', y='adj_True', color='red', ax=ax)

# adjust=False (초록색)
df3_adj.plot(kind='line', x='Date', y='adj_False', color='green', ax=ax)

plt.ylim(df_20['Close'].min() * 0.95, df_20['Close'].max() * 1.05)


plt.xticks(rotation=45)
plt.show()
```




<img width="550" height="457" alt="26 01 27 데일리미션_22_0" src="https://github.com/user-attachments/assets/2f85ffc0-f048-4f79-8e43-68ff28fad4fa" />




    


#**ignore_na인수 사용**


```python
# ignore_na 인수
df2_na = df_20.assign(ignore_na_True=df_20['Close'].ewm(alpha=0.2, ignore_na=True).mean())
df3_na = df_20.assign(ignore_na_False=df_20['Close'].ewm(alpha=0.2, ignore_na=False).mean())

# 시각화
ax = df_20.plot(kind='bar', x='Date', y='Close')

# ignore_na=True (빨간색)
df2_na.plot(kind='line', x='Date', y='ignore_na_True', color='red', ax=ax)

# ignore_na=False (초록색)
df3_na.plot(kind='line', x='Date', y='ignore_na_False', color='green', ax=ax)

plt.ylim(df_20['Close'].min() * 0.95, df_20['Close'].max() * 1.05)
plt.xticks(rotation=45)

plt.show()
```


    
    
<img width="550" height="457" alt="26 01 27 데일리미션_24_0" src="https://github.com/user-attachments/assets/7cc92c20-1ccc-4d9a-b03b-3722092ddb78" />






#**그룹화 계산(Groupby) 파라미터 활용**


- agg: 여러 연산 수행,연도별 주가 평균과 최대 변동폭 동시 확인
- as_index: 결과 가공 용이,그룹화 결과를 바로 **차트(x축)**로 그릴 때 편리
- group_keys: 깔끔한 출력,apply 사용 시 인덱스가 지저분해지는 것 방지
- observed:
- dropna: 결측값 체크,날짜 누락이 있는 행도 통계에 포함시켜 확인

#**agg 활용**


```python
# 연도별로 그룹화

df['Year'] = df['Date'].dt.year
result = df.groupby('Year').agg({'Close': ['mean', 'max'], 'Volume': 'sum'})
print(result)
```

              Close                   Volume
               mean        max           sum
    Year                                    
    2013  49.657568  73.309998  8.456966e+08
    2014  45.451508  69.000000  5.863498e+09
    2015  35.344325  52.869999  5.342558e+09
    2016  17.571111  24.870001  6.470728e+09
    2017  17.823506  25.200001  4.400015e+09
    2018  32.828526  46.759998  7.158662e+09
    2019  35.575476  45.419998  3.887246e+09
    2020  37.215771  55.869999  4.964256e+09
    2021  59.991746  77.629997  4.239006e+09
    2022  41.034783  53.700001  5.965786e+09


#**as_index, dropna 활용**


```python
# 기존 인덱스 유지, NaN이 있어도 포함

year_count = df.groupby('Year', as_index=False, dropna=False).count()
print(year_count)
```

       Year  Date  Open  High  Low  Close  Adj Close  Volume
    0  2013    37    37    37   37     37         37      37
    1  2014   252   252   252  252    252        252     252
    2  2015   252   252   252  252    252        252     252
    3  2016   252   252   252  252    252        252     252
    4  2017   251   251   251  251    251        251     251
    5  2018   251   251   251  251    251        251     251
    6  2019   252   252   252  252    252        252     252
    7  2020   253   253   253  253    253        253     253
    8  2021   252   252   252  252    252        252     252
    9  2022   212   207   207  207    207        207     207


#**apply와 group_keys 활용**


```python
# 각 연도별로 가장 주가가 높았던 날 2개 뽑기
# 인덱스 중복을 막기 위해 group_keys=False 사용

def top_prices(group):
    return group.sort_values(by='Close', ascending=False).head(2)

# group_keys=False를 써서 인덱스에 Year가 중복 표시되는 것을 방지
days = df.groupby('Year', group_keys=False).apply(top_prices)
print(days[['Date', 'Close']])
```

               Date      Close
    33   2013-12-26  73.309998
    32   2013-12-24  69.959999
    38   2014-01-03  69.000000
    37   2014-01-02  67.500000
    353  2015-04-07  52.869999
    354  2015-04-08  52.299999
    732  2016-10-05  24.870001
    730  2016-10-03  24.000000
    1037 2017-12-20  25.200001
    1036 2017-12-19  25.080000
    1157 2018-06-14  46.759998
    1172 2018-07-06  46.650002
    1466 2019-09-06  45.419998
    1465 2019-09-05  45.299999
    1791 2020-12-18  55.869999
    1793 2020-12-22  54.910000
    1838 2021-03-01  77.629997
    1837 2021-02-26  77.059998
    2258 2022-10-27  53.700001
    2257 2022-10-26  53.349998


    /tmp/ipython-input-1699590838.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
      days = df.groupby('Year', group_keys=False).apply(top_prices)


#**observed 활용**


```python
# 없는 연도(2030년)를 넣어두기
years_cat = pd.Categorical(df['Year'], categories=[2020, 2021, 2022, 2030])

# observed=False: 데이터에 없는 값도 표시됨
result = df['Close'].groupby(years_cat, observed=False).mean()
print(result)
```

    2020    37.215771
    2021    59.991746
    2022    41.034783
    2030          NaN
    Name: Close, dtype: float64


#**level 활용**


```python
# Year과 Month를 멀티 인덱스로
df['Month'] = df['Date'].dt.month
multi = df.set_index(['Year', 'Month'])

# level=0(Year)으로 그룹화한 후 합계 계산
sum = multi.groupby('Year')[['Close', 'Volume']].sum()

# level=1(Month)로 그룹화한 후 평균 계산
avg = multi.groupby(level='Month').mean()

print(sum)
```

                 Close        Volume
    Year                            
    2013   1837.330005  8.456966e+08
    2014  11453.780019  5.863498e+09
    2015   8906.769955  5.342558e+09
    2016   4427.919996  6.470728e+09
    2017   4473.700016  4.400015e+09
    2018   8239.960001  7.158662e+09
    2019   8965.020024  3.887246e+09
    2020   9415.589986  4.964256e+09
    2021  15117.919987  4.239006e+09
    2022   8494.199994  5.965786e+09



```python
print(avg)
```

                                   Date       Open       High        Low  \
    Month                                                                  
    1     2018-01-12 10:25:03.296703232  34.781647  35.493441  34.022711   
    2     2018-02-10 01:32:05.581395456  37.236076  38.108460  36.537116   
    3     2018-04-01 14:18:10.909090816  36.612836  37.289494  35.714257   
    4     2018-04-11 21:09:40.645161216  37.225323  37.978307  36.325184   
    5     2018-05-11 15:29:31.428571392  33.242373  33.813328  32.689824   
    6     2018-06-11 18:24:14.922279680  35.330104  35.939043  34.773179   
    7     2018-07-07 02:01:15.789473792  37.257105  37.962567  36.648875   
    8     2018-08-27 02:39:11.758793984  36.320879  36.851657  35.811020   
    9     2018-09-16 04:40:12.972973056  37.335541  37.950489  36.722215   
    10    2018-10-01 09:05:27.272727296  37.825295  38.570803  37.081696   
    11    2018-01-30 04:29:00.659340544  33.724259  34.304510  33.060677   
    12    2017-12-15 12:22:44.210526208  35.242159  36.045984  34.571913   
    
               Close  Adj Close        Volume  
    Month                                      
    1      34.719615  34.719615  1.908570e+07  
    2      37.349825  37.349825  2.643039e+07  
    3      36.410454  36.410454  1.903777e+07  
    4      37.082957  37.082957  3.179083e+07  
    5      33.231958  33.231958  2.213065e+07  
    6      35.405751  35.405751  2.124969e+07  
    7      37.305684  37.305684  2.365206e+07  
    8      36.333668  36.333668  1.650318e+07  
    9      37.341730  37.341730  1.811900e+07  
    10     37.815459  37.815459  2.728784e+07  
    11     33.626425  33.626425  1.795682e+07  
    12     35.318632  35.318632  1.820339e+07  

